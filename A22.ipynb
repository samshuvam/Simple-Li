{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Importing necessary libraries and loading the dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "At3U9vKUleVd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the California Housing dataset as an alternative\n",
        "housing = datasets.fetch_california_housing()\n",
        "df = pd.DataFrame(data=housing['data'], columns=housing['feature_names'])\n",
        "df['PRICE'] = housing['target']"
      ],
      "metadata": {
        "id": "bHVxNAwnlfiT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Identifying the best attribute for linear regression\n",
        "correlation_matrix = df.corr()\n",
        "best_attribute = correlation_matrix['PRICE'].abs().idxmax()\n",
        "print(f\"The attribute best correlated with the price is: {best_attribute}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvFfaBgolg3I",
        "outputId": "c34ab2a7-ab8f-4ae7-9a57-4d38810690f9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The attribute best correlated with the price is: PRICE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Splitting the dataset into training and testing sets\n",
        "X = df[[best_attribute]].values\n",
        "y = df['PRICE'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
      ],
      "metadata": {
        "id": "TX7sE80eljUq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Implementing the Analytic Solution (Normal Equation)\n",
        "X_b = np.c_[np.ones((X_train.shape[0], 1)), X_train]\n",
        "theta_analytic = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y_train"
      ],
      "metadata": {
        "id": "NefWE1TWlkld"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Implementing Gradient Descent (Full-batch)\n",
        "def gradient_descent_full(X, y, learning_rate=0.01, epochs=1000):\n",
        "    m = X.shape[0]\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    theta = np.random.randn(2)\n",
        "    for epoch in range(epochs):\n",
        "        gradients = 2/m * X_b.T @ (X_b @ theta - y)\n",
        "        theta -= learning_rate * gradients\n",
        "    return theta\n",
        "\n",
        "theta_gd_full = gradient_descent_full(X_train, y_train)"
      ],
      "metadata": {
        "id": "GUjv9WWelmB4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Implementing Stochastic Gradient Descent\n",
        "def gradient_descent_stochastic(X, y, learning_rate=0.01, epochs=1000):\n",
        "    m = X.shape[0]\n",
        "    X_b = np.c_[np.ones((m, 1)), X]\n",
        "    theta = np.random.randn(2)  # Initialize theta\n",
        "    for epoch in range(epochs):\n",
        "        for i in range(m):\n",
        "            random_index = np.random.randint(m)\n",
        "            xi = X_b[random_index:random_index+1]\n",
        "            yi = y[random_index:random_index+1]\n",
        "            gradients = 2 * xi.T @ (xi @ theta - yi)\n",
        "            theta -= learning_rate * gradients\n",
        "    return theta\n",
        "\n",
        "theta_gd_stochastic = gradient_descent_stochastic(X_train, y_train)"
      ],
      "metadata": {
        "id": "8QYbIT0QloDb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVIc3S15_z2w",
        "outputId": "08d6f71f-62b1-4c00-e522-1578acd3695d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analytic Solution: [7.2971143e-15 1.0000000e+00]\n",
            "Gradient Descent (Full-batch): [-0.012305  1.004703]\n",
            "Stochastic Gradient Descent: [-4.31051686e-16  1.00000000e+00]\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Comparing the Results\n",
        "print(\"Analytic Solution:\", theta_analytic)\n",
        "print(\"Gradient Descent (Full-batch):\", theta_gd_full)\n",
        "print(\"Stochastic Gradient Descent:\", theta_gd_stochastic)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}